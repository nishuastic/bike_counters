{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "# subprocess.run([\n",
    "#     \"latitude\", \"longitude\", \"year\", \"month\", \"day\", \"weekday\", \"hour\",\n",
    "#     \"is_weekend\", \"is_holiday\", \"strike\", \"lockdown\", \"TimeOfDay\", \"Season\"\n",
    "# ])\n",
    "import data_cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5504899446110724\n"
     ]
    }
   ],
   "source": [
    "problem_title = \"Bike count prediction\"\n",
    "_target_column_name = \"log_bike_count\"\n",
    "\n",
    "X, y = data_cleaning.get_train_data(path=\"data/train.parquet\")\n",
    "\n",
    "X_train_split, y_train_split, X_test_split, y_test_split = data_cleaning.train_test_split_temporal(X, y)\n",
    "\n",
    "# Define encoders and preprocessors\n",
    "columns_encoder = FunctionTransformer(data_cleaning._select_columns)\n",
    "date_encoder = FunctionTransformer(data_cleaning._encode_dates)\n",
    "strike_encoder = FunctionTransformer(data_cleaning._add_strike)\n",
    "lockdown_encoder = FunctionTransformer(data_cleaning._add_lockdown)\n",
    "time_of_day_encoder = FunctionTransformer(data_cleaning._add_time_of_day)\n",
    "season_encoder = FunctionTransformer(data_cleaning._add_season)\n",
    "erase_date = FunctionTransformer(data_cleaning.erase_date)\n",
    "\n",
    "ordinal_cols = [\"counter_installation_date\", \"counter_id\"]\n",
    "scale_cols = [\n",
    "    \"latitude\", \"longitude\", \"year\", \"month\", \"day\", \"weekday\", \"hour\",\n",
    "    \"is_weekend\", \"is_holiday\", \"strike\", \"lockdown\", \"TimeOfDay\", \"Season\"\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "ordinal = OrdinalEncoder()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"num\", scaler, scale_cols),\n",
    "        (\"ordinal\", ordinal, ordinal_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "regressor = XGBRegressor(random_state=42)\n",
    "# Create the pipeline\n",
    "pipe = make_pipeline(\n",
    "    columns_encoder,\n",
    "    date_encoder,\n",
    "    strike_encoder,\n",
    "    lockdown_encoder,\n",
    "    time_of_day_encoder,\n",
    "    season_encoder,\n",
    "    erase_date,\n",
    "    preprocessor,\n",
    "    regressor,\n",
    ")\n",
    "\n",
    "# Fit the pipeline\n",
    "pipe.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = pipe.predict(X_test_split)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_split, y_pred))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test = get_test_data()\n",
    "original_index = final_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(final_test)\n",
    "results = pd.DataFrame(\n",
    "    dict(\n",
    "        Id=original_index,\n",
    "        log_bike_count=y_pred,\n",
    "    )\n",
    ")\n",
    "results.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 245\n",
      "[LightGBM] [Info] Number of data points in the train set: 456507, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 3.048868\n",
      "RMSE of Stacking Pipeline: 0.54673\n",
      "Submission file saved at: submission_stacked_pipeline.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, OrdinalEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Custom transformer for stacking\n",
    "class StackingTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, rf_model, lgb_model):\n",
    "        self.rf_model = rf_model\n",
    "        self.lgb_model = lgb_model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Fit base models on training data\n",
    "        self.rf_model.fit(X, y)\n",
    "        self.lgb_model.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Generate predictions from base models\n",
    "        rf_pred = self.rf_model.predict(X)\n",
    "        lgb_pred = self.lgb_model.predict(X)\n",
    "        # Combine predictions into stacked features\n",
    "        return np.vstack((rf_pred, lgb_pred)).T\n",
    "\n",
    "\n",
    "# Base models\n",
    "rf_model = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42, n_jobs=-1)\n",
    "lgb_model = LGBMRegressor(random_state=42)\n",
    "\n",
    "# Meta-model\n",
    "xgb_meta_model = XGBRegressor(random_state=42)\n",
    "\n",
    "# Define encoders and preprocessors\n",
    "columns_encoder = FunctionTransformer(data_cleaning._select_columns)\n",
    "date_encoder = FunctionTransformer(data_cleaning._encode_dates)\n",
    "strike_encoder = FunctionTransformer(data_cleaning._add_strike)\n",
    "lockdown_encoder = FunctionTransformer(data_cleaning._add_lockdown)\n",
    "time_of_day_encoder = FunctionTransformer(data_cleaning._add_time_of_day)\n",
    "season_encoder = FunctionTransformer(data_cleaning._add_season)\n",
    "erase_date = FunctionTransformer(data_cleaning.erase_date)\n",
    "\n",
    "ordinal_cols = [\"counter_installation_date\", \"counter_id\"]\n",
    "scale_cols = [\n",
    "    \"latitude\", \"longitude\", \"year\", \"month\", \"day\", \"weekday\", \"hour\",\n",
    "    \"is_weekend\", \"is_holiday\", \"strike\", \"lockdown\", \"TimeOfDay\", \"Season\"\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "ordinal = OrdinalEncoder()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"num\", scaler, scale_cols),\n",
    "        (\"ordinal\", ordinal, ordinal_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pipeline for stacking\n",
    "stacking_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"columns_encoder\", columns_encoder),\n",
    "        (\"date_encoder\", date_encoder),\n",
    "        (\"strike_encoder\", strike_encoder),\n",
    "        (\"lockdown_encoder\", lockdown_encoder),\n",
    "        (\"time_of_day_encoder\", time_of_day_encoder),\n",
    "        (\"season_encoder\", season_encoder),\n",
    "        (\"erase_date\", erase_date),\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"stacking\", StackingTransformer(rf_model=rf_model, lgb_model=lgb_model)),\n",
    "        (\"meta_model\", xgb_meta_model),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train the pipeline\n",
    "stacking_pipeline.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Evaluate the pipeline\n",
    "y_pred = stacking_pipeline.predict(X_test_split)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_split, y_pred))\n",
    "print(f\"RMSE of Stacking Pipeline: {rmse:.5f}\")\n",
    "\n",
    "# Predict on final test set\n",
    "final_test = data_cleaning.get_test_data(path=\"data/final_test.parquet\")\n",
    "original_index = final_test.index\n",
    "final_test_predictions = stacking_pipeline.predict(final_test)\n",
    "\n",
    "# Create a submission file\n",
    "submission = pd.DataFrame({\"id\": original_index, \"log_bike_count\": final_test_predictions.flatten()})\n",
    "submission_path = \"submission_stacked_pipeline.csv\"\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"Submission file saved at: {submission_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
