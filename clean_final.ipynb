{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "\n",
    "import holidays\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counter_id</th>\n",
       "      <th>counter_name</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_name</th>\n",
       "      <th>date</th>\n",
       "      <th>counter_installation_date</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>counter_technical_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400125</th>\n",
       "      <td>100049407-353255860</td>\n",
       "      <td>152 boulevard du Montparnasse E-O</td>\n",
       "      <td>100049407</td>\n",
       "      <td>152 boulevard du Montparnasse</td>\n",
       "      <td>2020-09-01 01:00:00</td>\n",
       "      <td>2018-12-07</td>\n",
       "      <td>48.840801,2.333233</td>\n",
       "      <td>Y2H19070373</td>\n",
       "      <td>48.840801</td>\n",
       "      <td>2.333233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408305</th>\n",
       "      <td>100049407-353255859</td>\n",
       "      <td>152 boulevard du Montparnasse O-E</td>\n",
       "      <td>100049407</td>\n",
       "      <td>152 boulevard du Montparnasse</td>\n",
       "      <td>2020-09-01 01:00:00</td>\n",
       "      <td>2018-12-07</td>\n",
       "      <td>48.840801,2.333233</td>\n",
       "      <td>Y2H19070373</td>\n",
       "      <td>48.840801</td>\n",
       "      <td>2.333233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 counter_id                       counter_name    site_id  \\\n",
       "400125  100049407-353255860  152 boulevard du Montparnasse E-O  100049407   \n",
       "408305  100049407-353255859  152 boulevard du Montparnasse O-E  100049407   \n",
       "\n",
       "                            site_name                date  \\\n",
       "400125  152 boulevard du Montparnasse 2020-09-01 01:00:00   \n",
       "408305  152 boulevard du Montparnasse 2020-09-01 01:00:00   \n",
       "\n",
       "       counter_installation_date         coordinates counter_technical_id  \\\n",
       "400125                2018-12-07  48.840801,2.333233          Y2H19070373   \n",
       "408305                2018-12-07  48.840801,2.333233          Y2H19070373   \n",
       "\n",
       "         latitude  longitude  \n",
       "400125  48.840801   2.333233  \n",
       "408305  48.840801   2.333233  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "X, y = utils.get_train_data()\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _encode_dates(X):\n",
    "    X = X.copy()  # Modify a copy of X\n",
    "    \n",
    "    # Ensure 'date' is in datetime format\n",
    "    X[\"date\"] = pd.to_datetime(X[\"date\"])\n",
    "    \n",
    "    # Extract date components\n",
    "    X[\"year\"] = X[\"date\"].dt.year\n",
    "    X[\"month\"] = X[\"date\"].dt.month\n",
    "    X[\"day\"] = X[\"date\"].dt.day\n",
    "    X[\"weekday\"] = X[\"date\"].dt.weekday\n",
    "    X[\"hour\"] = X[\"date\"].dt.hour\n",
    "\n",
    "    # Identify weekends (Saturday = 5, Sunday = 6)\n",
    "    X[\"is_weekend\"] = X[\"weekday\"].isin([5, 6])\n",
    "    \n",
    "    # Get French holidays for all years in the dataset\n",
    "    years = X[\"year\"].unique()\n",
    "    fr_holidays = holidays.France(years=years)\n",
    "    \n",
    "    # Identify holidays\n",
    "    X[\"is_holiday\"] = X[\"date\"].dt.date.isin(fr_holidays)\n",
    "    \n",
    "    # Drop the original 'date' column\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counter_id</th>\n",
       "      <th>counter_name</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_name</th>\n",
       "      <th>date</th>\n",
       "      <th>counter_installation_date</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>counter_technical_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400125</th>\n",
       "      <td>100049407-353255860</td>\n",
       "      <td>152 boulevard du Montparnasse E-O</td>\n",
       "      <td>100049407</td>\n",
       "      <td>152 boulevard du Montparnasse</td>\n",
       "      <td>2020-09-01 01:00:00</td>\n",
       "      <td>2018-12-07</td>\n",
       "      <td>48.840801,2.333233</td>\n",
       "      <td>Y2H19070373</td>\n",
       "      <td>48.840801</td>\n",
       "      <td>2.333233</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408305</th>\n",
       "      <td>100049407-353255859</td>\n",
       "      <td>152 boulevard du Montparnasse O-E</td>\n",
       "      <td>100049407</td>\n",
       "      <td>152 boulevard du Montparnasse</td>\n",
       "      <td>2020-09-01 01:00:00</td>\n",
       "      <td>2018-12-07</td>\n",
       "      <td>48.840801,2.333233</td>\n",
       "      <td>Y2H19070373</td>\n",
       "      <td>48.840801</td>\n",
       "      <td>2.333233</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 counter_id                       counter_name    site_id  \\\n",
       "400125  100049407-353255860  152 boulevard du Montparnasse E-O  100049407   \n",
       "408305  100049407-353255859  152 boulevard du Montparnasse O-E  100049407   \n",
       "\n",
       "                            site_name                date  \\\n",
       "400125  152 boulevard du Montparnasse 2020-09-01 01:00:00   \n",
       "408305  152 boulevard du Montparnasse 2020-09-01 01:00:00   \n",
       "\n",
       "       counter_installation_date         coordinates counter_technical_id  \\\n",
       "400125                2018-12-07  48.840801,2.333233          Y2H19070373   \n",
       "408305                2018-12-07  48.840801,2.333233          Y2H19070373   \n",
       "\n",
       "         latitude  longitude  year  month  day  weekday  hour  is_weekend  \\\n",
       "400125  48.840801   2.333233  2020      9    1        1     1       False   \n",
       "408305  48.840801   2.333233  2020      9    1        1     1       False   \n",
       "\n",
       "        is_holiday  \n",
       "400125       False  \n",
       "408305       False  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_encoder = FunctionTransformer(_encode_dates, validate=False)\n",
    "X = date_encoder.fit_transform(X)\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "627667    100056327-104056327\n",
       "675566    100056331-104056331\n",
       "685544    100056331-103056331\n",
       "264224    100047542-103047542\n",
       "273935    100047542-104047542\n",
       "313454    100047546-104047546\n",
       "323423    100047546-103047546\n",
       "595358    100056226-104056226\n",
       "608542    100056226-103056226\n",
       "635519    100056329-104056329\n",
       "Name: counter_id, dtype: category\n",
       "Categories (56, object): ['100007049-101007049', '100007049-102007049', '100036718-103036718', '100036718-104036718', ..., '100063175-353277233', '100063175-353277235', '300014702-353245971', '300014702-353245972']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['counter_id'][80:90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest date: 2020-09-01 01:00:00\n",
      "Latest date: 2021-09-09 23:00:00\n"
     ]
    }
   ],
   "source": [
    "# Ensure the 'date' column is in datetime format\n",
    "X['date'] = pd.to_datetime(X['date'])\n",
    "\n",
    "# Find the earliest and latest dates\n",
    "earliest_date = X['date'].min()\n",
    "latest_date = X['date'].max()\n",
    "\n",
    "print(f\"Earliest date: {earliest_date}\")\n",
    "print(f\"Latest date: {latest_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "strike_data = {'date': [datetime(2023, 2, 7), datetime(2023, 2, 16), datetime(2023, 3, 7),\n",
    "                 datetime(2023, 1, 31), datetime(2022, 2, 18), datetime(2022, 3, 25),\n",
    "                 datetime(2022, 5, 23), datetime(2022, 9, 29), datetime(2022, 10, 13)],\n",
    "                'Strike': [1] * 9}\n",
    "\n",
    "# Create a DataFrame\n",
    "strike = pd.DataFrame(strike_data)\n",
    "\n",
    "# Sort the values by ascending date\n",
    "strike.sort_values(by='date', inplace=True)\n",
    "strike.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Merge the strike DataFrame with df\n",
    "X = X.merge(strike, on='date', how='left')\n",
    "X['Strike'] = X['Strike'].fillna(0).astype(int)\n",
    "\n",
    "#Create get_TimeOfDay_name and get_TimeOfDay functions \n",
    "def get_TimeOfDay_name(hour):\n",
    "  \n",
    "  if hour > 3 and hour <= 6:\n",
    "    return 'Early morning 4:00AM - 6:00 AM'  \n",
    "  if hour > 6 and hour <= 10:\n",
    "    return 'Morning 7:00AM - 10:00 AM'\n",
    "  elif hour > 10 and hour <= 13:\n",
    "    return 'Middle of the day 11:00 AM - 1:00 PM'\n",
    "  elif hour > 13 and hour <= 17:\n",
    "    return 'Afternoon 2:00 PM - 5:00 PM'\n",
    "  elif hour > 17 and hour <= 22:\n",
    "    return 'Evening 6:00 PM - 10:00 PM'\n",
    "  else :\n",
    "    return 'Night 11:00 PM - 3:00 AM'\n",
    "  \n",
    "def get_TimeOfDay(hour):\n",
    "  if hour > 3 and hour <= 6:\n",
    "    return 1  \n",
    "  if hour > 6 and hour <= 10:\n",
    "    return 2\n",
    "  elif hour > 10 and hour <= 13:\n",
    "    return 3\n",
    "  elif hour > 13 and hour <= 17:\n",
    "    return 4\n",
    "  elif hour > 17 and hour <= 22:\n",
    "    return 5\n",
    "  else :\n",
    "    return 6\n",
    "\n",
    "#Create columns by applying the functions\n",
    "X['TimeOfDay'] = X['hour'].apply(get_TimeOfDay)\n",
    "X['TimeOfDay_name'] = X['hour'].apply(get_TimeOfDay_name)\n",
    "\n",
    "def get_season_name(date):\n",
    "  if (date > datetime(2022, 3, 20) ) & (date < datetime(2022, 6, 21)):\n",
    "    return 'Spring'\n",
    "  if (date > datetime(2022, 6, 20)) & (date < datetime(2022, 9, 21)):\n",
    "    return 'Summer'\n",
    "  if (date > datetime(2022, 9, 20)) & (date < datetime(2022, 12, 21)):\n",
    "      return 'Fall'\n",
    "  if  ((date > datetime(2022, 12, 20)) & (date < datetime(2023, 3, 20))) | ((date > datetime(2021, 12, 31)) & (date < datetime(2022, 3, 21))):\n",
    "      return 'Winter'\n",
    "\n",
    "def get_season(date):\n",
    "  if (date > datetime(2022, 3, 20) ) & (date < datetime(2022, 6, 21)):\n",
    "    return 1\n",
    "  if (date > datetime(2022, 6, 20)) & (date < datetime(2022, 9, 21)):\n",
    "    return 2\n",
    "  if (date > datetime(2022, 9, 20)) & (date < datetime(2022, 12, 21)):\n",
    "    return 3\n",
    "  if  ((date > datetime(2022, 12, 20)) & (date < datetime(2023, 3, 20))) | ((date > datetime(2021, 12, 31)) & (date < datetime(2022, 3, 21))):\n",
    "    return 4\n",
    "\n",
    "#Create columns by applying the functions\n",
    "X['Season'] = X['date'].apply(get_season)\n",
    "X['Season_name'] = X['date'].apply(get_season_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 496827 entries, 400125 to 135985\n",
      "Data columns (total 17 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   counter_id                 496827 non-null  category      \n",
      " 1   counter_name               496827 non-null  category      \n",
      " 2   site_id                    496827 non-null  int64         \n",
      " 3   site_name                  496827 non-null  category      \n",
      " 4   date                       496827 non-null  datetime64[us]\n",
      " 5   counter_installation_date  496827 non-null  datetime64[us]\n",
      " 6   coordinates                496827 non-null  category      \n",
      " 7   counter_technical_id       496827 non-null  category      \n",
      " 8   latitude                   496827 non-null  float64       \n",
      " 9   longitude                  496827 non-null  float64       \n",
      " 10  year                       496827 non-null  int32         \n",
      " 11  month                      496827 non-null  int32         \n",
      " 12  day                        496827 non-null  int32         \n",
      " 13  weekday                    496827 non-null  int32         \n",
      " 14  hour                       496827 non-null  int32         \n",
      " 15  is_weekend                 496827 non-null  bool          \n",
      " 16  is_holiday                 496827 non-null  bool          \n",
      "dtypes: bool(2), category(5), datetime64[us](2), float64(2), int32(5), int64(1)\n",
      "memory usage: 35.5 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counter_id</th>\n",
       "      <th>counter_name</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_name</th>\n",
       "      <th>date</th>\n",
       "      <th>counter_installation_date</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>counter_technical_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>...</th>\n",
       "      <th>hour_14</th>\n",
       "      <th>hour_15</th>\n",
       "      <th>hour_16</th>\n",
       "      <th>hour_17</th>\n",
       "      <th>hour_18</th>\n",
       "      <th>hour_19</th>\n",
       "      <th>hour_20</th>\n",
       "      <th>hour_21</th>\n",
       "      <th>hour_22</th>\n",
       "      <th>hour_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400125</th>\n",
       "      <td>100049407-353255860</td>\n",
       "      <td>152 boulevard du Montparnasse E-O</td>\n",
       "      <td>100049407</td>\n",
       "      <td>152 boulevard du Montparnasse</td>\n",
       "      <td>2020-09-01 01:00:00</td>\n",
       "      <td>2018-12-07</td>\n",
       "      <td>48.840801,2.333233</td>\n",
       "      <td>Y2H19070373</td>\n",
       "      <td>48.840801</td>\n",
       "      <td>2.333233</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408305</th>\n",
       "      <td>100049407-353255859</td>\n",
       "      <td>152 boulevard du Montparnasse O-E</td>\n",
       "      <td>100049407</td>\n",
       "      <td>152 boulevard du Montparnasse</td>\n",
       "      <td>2020-09-01 01:00:00</td>\n",
       "      <td>2018-12-07</td>\n",
       "      <td>48.840801,2.333233</td>\n",
       "      <td>Y2H19070373</td>\n",
       "      <td>48.840801</td>\n",
       "      <td>2.333233</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 counter_id                       counter_name    site_id  \\\n",
       "400125  100049407-353255860  152 boulevard du Montparnasse E-O  100049407   \n",
       "408305  100049407-353255859  152 boulevard du Montparnasse O-E  100049407   \n",
       "\n",
       "                            site_name                date  \\\n",
       "400125  152 boulevard du Montparnasse 2020-09-01 01:00:00   \n",
       "408305  152 boulevard du Montparnasse 2020-09-01 01:00:00   \n",
       "\n",
       "       counter_installation_date         coordinates counter_technical_id  \\\n",
       "400125                2018-12-07  48.840801,2.333233          Y2H19070373   \n",
       "408305                2018-12-07  48.840801,2.333233          Y2H19070373   \n",
       "\n",
       "         latitude  longitude  ...  hour_14  hour_15  hour_16  hour_17  \\\n",
       "400125  48.840801   2.333233  ...    False    False    False    False   \n",
       "408305  48.840801   2.333233  ...    False    False    False    False   \n",
       "\n",
       "        hour_18  hour_19  hour_20  hour_21  hour_22  hour_23  \n",
       "400125    False    False    False    False    False    False  \n",
       "408305    False    False    False    False    False    False  \n",
       "\n",
       "[2 rows x 40 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.get_dummies(X, columns=[\"hour\"], prefix=\"hour\")\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 496827 entries, 400125 to 135985\n",
      "Data columns (total 40 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   counter_id                 496827 non-null  category      \n",
      " 1   counter_name               496827 non-null  category      \n",
      " 2   site_id                    496827 non-null  int64         \n",
      " 3   site_name                  496827 non-null  category      \n",
      " 4   date                       496827 non-null  datetime64[us]\n",
      " 5   counter_installation_date  496827 non-null  datetime64[us]\n",
      " 6   coordinates                496827 non-null  category      \n",
      " 7   counter_technical_id       496827 non-null  category      \n",
      " 8   latitude                   496827 non-null  float64       \n",
      " 9   longitude                  496827 non-null  float64       \n",
      " 10  year                       496827 non-null  int32         \n",
      " 11  month                      496827 non-null  int32         \n",
      " 12  day                        496827 non-null  int32         \n",
      " 13  weekday                    496827 non-null  int32         \n",
      " 14  is_weekend                 496827 non-null  bool          \n",
      " 15  is_holiday                 496827 non-null  bool          \n",
      " 16  hour_0                     496827 non-null  bool          \n",
      " 17  hour_1                     496827 non-null  bool          \n",
      " 18  hour_2                     496827 non-null  bool          \n",
      " 19  hour_3                     496827 non-null  bool          \n",
      " 20  hour_4                     496827 non-null  bool          \n",
      " 21  hour_5                     496827 non-null  bool          \n",
      " 22  hour_6                     496827 non-null  bool          \n",
      " 23  hour_7                     496827 non-null  bool          \n",
      " 24  hour_8                     496827 non-null  bool          \n",
      " 25  hour_9                     496827 non-null  bool          \n",
      " 26  hour_10                    496827 non-null  bool          \n",
      " 27  hour_11                    496827 non-null  bool          \n",
      " 28  hour_12                    496827 non-null  bool          \n",
      " 29  hour_13                    496827 non-null  bool          \n",
      " 30  hour_14                    496827 non-null  bool          \n",
      " 31  hour_15                    496827 non-null  bool          \n",
      " 32  hour_16                    496827 non-null  bool          \n",
      " 33  hour_17                    496827 non-null  bool          \n",
      " 34  hour_18                    496827 non-null  bool          \n",
      " 35  hour_19                    496827 non-null  bool          \n",
      " 36  hour_20                    496827 non-null  bool          \n",
      " 37  hour_21                    496827 non-null  bool          \n",
      " 38  hour_22                    496827 non-null  bool          \n",
      " 39  hour_23                    496827 non-null  bool          \n",
      "dtypes: bool(26), category(5), datetime64[us](2), float64(2), int32(4), int64(1)\n",
      "memory usage: 45.0 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_temporal(X, y, delta_threshold=\"30 days\"):\n",
    "    \n",
    "    cutoff_date = X[\"date\"].max() - pd.Timedelta(delta_threshold)\n",
    "    mask = (X[\"date\"] <= cutoff_date)\n",
    "    X_train, X_valid = X.loc[mask], X.loc[~mask]\n",
    "    y_train, y_valid = y[mask], y[~mask]\n",
    "\n",
    "    return X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with datetime64[ns] dtype: ['feature_0', 'feature_1', 'date']\n",
      "Columns with datetime64[ns] dtype: ['feature_0', 'feature_1', 'date']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Preprocessing\n",
    "# One-hot encode the categorical variables\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "onehot_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "categorical_encoded = onehot_encoder.fit_transform(X[categorical_cols])\n",
    "\n",
    "# Numerical scaling\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "scaler = MinMaxScaler()\n",
    "numerical_scaled = scaler.fit_transform(X[numerical_cols])\n",
    "\n",
    "# Drop processed columns\n",
    "X.drop(categorical_cols, axis=1, inplace=True)\n",
    "X.drop(numerical_cols, axis=1, inplace=True)\n",
    "\n",
    "# Ensure date column is in datetime format\n",
    "X[\"date\"] = pd.to_datetime(X[\"date\"])\n",
    "\n",
    "# Combine all features\n",
    "X_combined = np.hstack([X.values, categorical_encoded, numerical_scaled])\n",
    "\n",
    "# Assuming each sample has a single timestep\n",
    "\n",
    "# Step 3: Temporal Train-Test Split\n",
    "# Convert X_reshaped back into a DataFrame to preserve the date column\n",
    "X_combined_df = pd.DataFrame(X_combined, columns=[f\"feature_{i}\" for i in range(X_combined.shape[1])])\n",
    "X_combined_df[\"date\"] = X[\"date\"].values  # Restore the date column\n",
    "\n",
    "\n",
    "# Apply temporal train-test split\n",
    "X_train_split, y_train_split, X_test_split, y_test_split = train_test_split_temporal(X_combined_df, y)\n",
    "\n",
    "\n",
    "# Remove the 'date' column after splitting\n",
    "datetime_columns = X_test_split.select_dtypes(include=['datetime64[ns]']).columns\n",
    "print(f\"Columns with datetime64[ns] dtype: {datetime_columns.tolist()}\")\n",
    "datetime_columns = X_test_split.select_dtypes(include=['datetime64[ns]']).columns\n",
    "print(f\"Columns with datetime64[ns] dtype: {datetime_columns.tolist()}\")\n",
    "\n",
    "# Drop these columns from X_train_split\n",
    "X_train_split = X_train_split.drop(columns=datetime_columns)\n",
    "# Drop these columns from X_test_split\n",
    "X_test_split = X_test_split.drop(columns=datetime_columns)\n",
    "\n",
    "X_train_split = X_train_split.astype(float)\n",
    "X_test_split = X_test_split.astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with datetime64[ns] dtype: ['feature_0', 'feature_1', 'date']\n"
     ]
    }
   ],
   "source": [
    "final_test = utils.get_test_data()\n",
    "date_encoder = FunctionTransformer(_encode_dates, validate=False)\n",
    "final_test = date_encoder.fit_transform(final_test)\n",
    "final_test = pd.get_dummies(final_test, columns=[\"hour\"], prefix=\"hour\")\n",
    "# final_test.head(2)\n",
    "\n",
    "# Step 1: Preprocessing\n",
    "# One-hot encode the categorical variables\n",
    "\n",
    "# final_test = final_test.merge(strike, on='date', how='left')\n",
    "# final_test['Strike'] = final_test['Strike'].fillna(0).astype(int)\n",
    "\n",
    "# final_test['TimeOfDay'] = final_test['hour'].apply(get_TimeOfDay)\n",
    "# final_test['TimeOfDay_name'] = final_test['hour'].apply(get_TimeOfDay_name)\n",
    "\n",
    "# final_test['Season'] = final_test['date'].apply(get_season)\n",
    "# final_test['Season_name'] = final_test['date'].apply(get_season_name)\n",
    "\n",
    "categorical_cols = final_test.select_dtypes(include=['object', 'category']).columns\n",
    "onehot_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "categorical_encoded = onehot_encoder.fit_transform(final_test[categorical_cols])\n",
    "\n",
    "# Numerical scaling\n",
    "numerical_cols = final_test.select_dtypes(include=['int64', 'float64']).columns\n",
    "scaler = MinMaxScaler()\n",
    "numerical_scaled = scaler.fit_transform(final_test[numerical_cols])\n",
    "\n",
    "# Drop processed columns\n",
    "final_test.drop(categorical_cols, axis=1, inplace=True)\n",
    "final_test.drop(numerical_cols, axis=1, inplace=True)\n",
    "\n",
    "# Ensure date column is in datetime format\n",
    "final_test[\"date\"] = pd.to_datetime(final_test[\"date\"])\n",
    "\n",
    "# Combine all features\n",
    "final_test_combined = np.hstack([final_test.values, categorical_encoded, numerical_scaled])\n",
    "\n",
    "# Assuming each sample has a single timestep\n",
    "\n",
    "# Convert X_reshaped back into a DataFrame to preserve the date column\n",
    "final_test_combined = pd.DataFrame(final_test_combined, columns=[f\"feature_{i}\" for i in range(final_test_combined.shape[1])])\n",
    "final_test_combined[\"date\"] = final_test[\"date\"].values  # Restore the date column\n",
    "\n",
    "\n",
    "datetime_columns = final_test_combined.select_dtypes(include=['datetime64[ns]']).columns\n",
    "print(f\"Columns with datetime64[ns] dtype: {datetime_columns.tolist()}\")\n",
    "\n",
    "final_test_combined = final_test_combined.drop(columns=datetime_columns)\n",
    "\n",
    "final_test_combined = final_test_combined.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: XGBoost, RMSE: 0.5126279064139162\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 456507, number of used features: 235\n",
      "[LightGBM] [Info] Start training from score 3.048868\n",
      "Model: LightGBM, RMSE: 0.5368720878935426\n",
      "              RMSE\n",
      "XGBoost   0.512628\n",
      "LightGBM  0.536872\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"XGBoost\": xgb.XGBRegressor(random_state=42, verbosity=1),\n",
    "    \"LightGBM\": lgb.LGBMRegressor(random_state=42),\n",
    "    # \"Random Forest\": RandomForestRegressor(\n",
    "    #     n_estimators=100,  # Fewer trees\n",
    "    #     max_depth=20,     # Limit depth\n",
    "    #     min_samples_split=5,\n",
    "    #     min_samples_leaf=2,\n",
    "    #     random_state=42,\n",
    "    #     n_jobs=-1         # Utilize multiple cores\n",
    "    # ),\n",
    "}\n",
    "\n",
    "# Initialize a dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train_split, y_train_split)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test_split)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_split, y_pred))\n",
    "    results[name] = rmse\n",
    "    print(f\"Model: {name}, RMSE: {rmse}\")\n",
    "\n",
    "# Convert results to a DataFrame and display\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index', columns=['RMSE']).sort_values(by='RMSE')\n",
    "\n",
    "# Display the results\n",
    "print(results_df)\n",
    "\n",
    "for name, model in models.items():\n",
    "    predictions = model.predict(final_test_combined)\n",
    "    submission = pd.DataFrame({\"id\": final_test.index, \"log_bike_count\": predictions.flatten()})\n",
    "    submission_path = f\"submission_{name}.csv\"\n",
    "    submission.to_csv(submission_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 12\u001b[0m\n\u001b[1;32m      2\u001b[0m rf \u001b[38;5;241m=\u001b[39m  RandomForestRegressor(\n\u001b[1;32m      3\u001b[0m         n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,  \u001b[38;5;66;03m# Fewer trees\u001b[39;00m\n\u001b[1;32m      4\u001b[0m         max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,     \u001b[38;5;66;03m# Limit depth\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m         \u001b[38;5;66;03m# Utilize multiple cores\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     )\n\u001b[1;32m     10\u001b[0m lgb_model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m rf\u001b[38;5;241m.\u001b[39mfit(X_train_split, y_train_split)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# xgb_model.fit(X_train_split, y_train_split)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m lgb_model\u001b[38;5;241m.\u001b[39mfit(X_train_split, y_train_split)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    481\u001b[0m ]\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[1;32m    490\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m    491\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    492\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    493\u001b[0m )(\n\u001b[1;32m    494\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    495\u001b[0m         t,\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[1;32m    497\u001b[0m         X,\n\u001b[1;32m    498\u001b[0m         y,\n\u001b[1;32m    499\u001b[0m         sample_weight,\n\u001b[1;32m    500\u001b[0m         i,\n\u001b[1;32m    501\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[1;32m    502\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    503\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[1;32m    504\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[1;32m    505\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    506\u001b[0m     )\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[1;32m    508\u001b[0m )\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train base models\n",
    "rf =  RandomForestRegressor(\n",
    "        n_estimators=100,  # Fewer trees\n",
    "        max_depth=20,     # Limit depth\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=42,\n",
    "        n_jobs=-1         # Utilize multiple cores\n",
    "    )\n",
    "lgb_model = lgb.LGBMRegressor(random_state=42)\n",
    "\n",
    "rf.fit(X_train_split, y_train_split)\n",
    "# xgb_model.fit(X_train_split, y_train_split)\n",
    "lgb_model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Generate predictions for stacking\n",
    "rf_pred = rf.predict(X_test_split)\n",
    "# xgb_pred = xgb_model.predict(X_test_split)\n",
    "lgb_pred = lgb_model.predict(X_test_split)\n",
    "\n",
    "# Combine predictions as input to the meta-model\n",
    "stacked_features = np.vstack((rf_pred, lgb_pred)).T\n",
    "\n",
    "# Train meta-model\n",
    "meta_model = xgb.XGBRegressor(random_state=42)\n",
    "meta_model.fit(stacked_features, y_test_split)\n",
    "\n",
    "# Final predictions\n",
    "final_pred = meta_model.predict(stacked_features)\n",
    "\n",
    "# Evaluate the stacked model\n",
    "rmse = np.sqrt(mean_squared_error(y_test_split, final_pred))\n",
    "print(f\"RMSE of Stacked Model: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = rf.predict(final_test_combined)\n",
    "lgb_pred = lgb_model.predict(final_test_combined)\n",
    "\n",
    "# Combine predictions as input to the meta-model\n",
    "stacked_features = np.vstack((rf_pred, lgb_pred)).T\n",
    "\n",
    "# Final predictions\n",
    "predictions = meta_model.predict(stacked_features)\n",
    "\n",
    "submission = pd.DataFrame({\"id\": final_test.index, \"log_bike_count\": predictions.flatten()})\n",
    "submission_path = \"submission_meta_model.csv\"\n",
    "submission.to_csv(submission_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
